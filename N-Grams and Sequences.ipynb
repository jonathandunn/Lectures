{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# N-Grams and Sequences\n",
    "\n",
    "We start by adding our previous functions to the workspace."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def read_corpus(file):\n",
    "    import codecs\n",
    "    with codecs.open(file, \"r\", encoding = \"utf-8\") as fo:\n",
    "        for line in fo:\n",
    "            yield line"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now read_corpus() creates a __generator__ that feeds lines from a file.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "This - here - is the first test sentence.\r\n",
      "\n",
      "This sentence: after the first test sentence!\r\n",
      "\n",
      "HERE IS THE THIRD (TEST) SENTENCE.\n"
     ]
    }
   ],
   "source": [
    "for line in read_corpus(\"./Corpora/eng.Test.txt\"):\n",
    "    print(line)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def tokenize(line_in):\n",
    "    \n",
    "    punctuation = ['\"', \".\", \",\", \"?\", \"!\", \"-\", \")\", \"(\", \":\", \";\"]\n",
    "    line_in = line_in.strip().lower()\n",
    "    line_out = \"\"\n",
    "\n",
    "    for char in line_in:\n",
    "        if char not in punctuation:\n",
    "            line_out += char\n",
    "\n",
    "    return line_out.replace(\"  \", \" \")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now tokenize() returns a lowercase string with certain symbols removed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "this here is the first test sentence\n",
      "this sentence after the first test sentence\n",
      "here is the third test sentence\n"
     ]
    }
   ],
   "source": [
    "for line in read_corpus(\"./Corpora/eng.Test.txt\"):\n",
    "    line = tokenize(line)\n",
    "    print(line)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "With _strings_ we can iterate over characters:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "T\n",
      "h\n",
      "i\n",
      "s\n",
      " \n",
      "i\n",
      "s\n",
      " \n",
      "a\n",
      " \n",
      "l\n",
      "i\n",
      "n\n",
      "e\n"
     ]
    }
   ],
   "source": [
    "for char in \"This is a line\":\n",
    "    print(char)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To iterate over words, we need to split the string. This creates a _list_ of words."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "This\n",
      "is\n",
      "a\n",
      "line\n"
     ]
    }
   ],
   "source": [
    "line = \"This is a line\"\n",
    "line_list = line.split(\" \")\n",
    "\n",
    "for word in line_list:\n",
    "        print(word)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "An __index__ refers to a specific location in a sequence. In Python, indexes begin at 0."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "T\n",
      "h\n"
     ]
    }
   ],
   "source": [
    "print(line[0])\n",
    "print(line[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Both strings and lists can be accessed by index."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "This\n",
      "is\n"
     ]
    }
   ],
   "source": [
    "print(line_list[0])\n",
    "print(line_list[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The _range()_ function iterates over integers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n",
      "2\n",
      "3\n",
      "4\n"
     ]
    }
   ],
   "source": [
    "for i in range(1, 5):\n",
    "    print(i)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The _len()_ function tells us how many units are in a sequence (for strings and lists)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "14\n",
      "4\n"
     ]
    }
   ],
   "source": [
    "print(len(line))\n",
    "print(len(line_list))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can iterate over a sequence by index by combining range() and len()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "T\n",
      "h\n",
      "i\n",
      "s\n",
      " \n",
      "i\n",
      "s\n",
      " \n",
      "a\n",
      " \n",
      "l\n",
      "i\n",
      "n\n",
      "e\n"
     ]
    }
   ],
   "source": [
    "for i in range(len(line)):\n",
    "    print(line[i])\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "This\n",
      "is\n",
      "a\n",
      "line\n"
     ]
    }
   ],
   "source": [
    "for i in range(len(line_list)):\n",
    "    print(line_list[i])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can use the index to find the _window_ of neighboring words or characters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "This is\n",
      "is a\n",
      "a line\n"
     ]
    }
   ],
   "source": [
    "for i in range(1, len(line_list)):\n",
    "    print(line_list[i-1], line_list[i])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "These sequences are called __n-grams__, where _n_ is the length. Bigrams have length 2. Trigrams have length 3."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can use this to make a function that takes a string and returns all the bigrams."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_bigrams(line):\n",
    "\n",
    "    bigrams = []  #Initialize list of bigrams\n",
    "    \n",
    "    line = tokenize(line)\n",
    "    line = line.split(\" \")\n",
    "\n",
    "    for i in range(1, len(line)):\n",
    "        bigrams.append((line[i-1], line[i]))\n",
    "        \n",
    "    return bigrams"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The function get_bigrams() allows us to easily collect bigrams across lines from a corpus."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('this', 'here'), ('here', 'is'), ('is', 'the'), ('the', 'first'), ('first', 'test'), ('test', 'sentence')]\n",
      "[('this', 'sentence'), ('sentence', 'after'), ('after', 'the'), ('the', 'first'), ('first', 'test'), ('test', 'sentence')]\n",
      "[('here', 'is'), ('is', 'the'), ('the', 'third'), ('third', 'test'), ('test', 'sentence')]\n"
     ]
    }
   ],
   "source": [
    "for line in read_corpus(\"./Corpora/eng.Test.txt\"):\n",
    "    print(get_bigrams(line))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here we see three _lists_, each containing a _tuple_ with two _strings_."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will count bigrams by using a _dictionary_.\n",
    "\n",
    "The keys of the dictionary will be bigrams and the values will be the current count."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from collections import defaultdict\n",
    "\n",
    "bigram_count = defaultdict(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "for line in read_corpus(\"./Corpora/eng.Test.txt\"):\n",
    "    for bigram in get_bigrams(line):\n",
    "        bigram_count[bigram] += 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can look at the contents of bigram_count using _keys()_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('this', 'here') 1\n",
      "('here', 'is') 2\n",
      "('is', 'the') 2\n",
      "('the', 'first') 2\n",
      "('first', 'test') 2\n",
      "('test', 'sentence') 3\n",
      "('this', 'sentence') 1\n",
      "('sentence', 'after') 1\n",
      "('after', 'the') 1\n",
      "('the', 'third') 1\n",
      "('third', 'test') 1\n"
     ]
    }
   ],
   "source": [
    "for key in bigram_count.keys():\n",
    "    print(key, bigram_count[key])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's make this a function so it can be reused."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def count_bigrams(filename):\n",
    "\n",
    "    corpus = read_corpus(filename)\n",
    "    bigram_count = defaultdict(int)\n",
    "\n",
    "    for line in corpus:\n",
    "        for bigram in get_bigrams(line):\n",
    "            bigram_count[bigram] += 1\n",
    "\n",
    "    return bigram_count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "defaultdict(<class 'int'>, {('this', 'here'): 1, ('here', 'is'): 2, ('is', 'the'): 2, ('the', 'first'): 2, ('first', 'test'): 2, ('test', 'sentence'): 3, ('this', 'sentence'): 1, ('sentence', 'after'): 1, ('after', 'the'): 1, ('the', 'third'): 1, ('third', 'test'): 1})\n"
     ]
    }
   ],
   "source": [
    "bigram_count = count_bigrams(\"./corpora/eng.Test.txt\")\n",
    "print(bigram_count)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we can view the bigrams by the most frequent."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('this', 'here')\n",
      "('this', 'sentence')\n",
      "('sentence', 'after')\n",
      "('after', 'the')\n",
      "('the', 'third')\n",
      "('third', 'test')\n"
     ]
    }
   ],
   "source": [
    "top_bigrams = sorted(bigram_count, key = bigram_count.get)\n",
    "\n",
    "for i in range(0, 6):\n",
    "    print(top_bigrams[i])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We have five real-world corpora in the ./corpora/ folder:\n",
    "    \n",
    "    eng.Europarl.txt: European Parliament proceedings\n",
    "    eng.NewsCommentary.txt: News articles and editorials\n",
    "    eng.OpenSubs.txt: Movie subtitles\n",
    "    eng.TED_Talks.txt: TED Talk scripts\n",
    "    eng.Web.txt: Web-crawled data\n",
    "    \n",
    "Each corpus contains about a million words. All are from the same language. Do they have the same top bigrams?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "europarl_bigrams = count_bigrams(\"./corpora/eng.Europarl.txt\")\n",
    "news_bigrams = count_bigrams(\"./corpora/eng.NewsCommentary.txt\")\n",
    "opensubs_bigrams = count_bigrams(\"./corpora/eng.OpenSubs.txt\")\n",
    "ted_bigrams = count_bigrams(\"./corpora/eng.TED_Talks.txt\")\n",
    "web_bigrams = count_bigrams(\"./corpora/eng.Web.txt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "top_europarl = sorted(europarl_bigrams, key = europarl_bigrams.get, reverse = True)\n",
    "top_news = sorted(news_bigrams, key = news_bigrams.get, reverse = True)\n",
    "top_opensubs = sorted(opensubs_bigrams, key = opensubs_bigrams.get, reverse = True)\n",
    "top_ted = sorted(ted_bigrams, key = ted_bigrams.get, reverse = True)\n",
    "top_web = sorted(web_bigrams, key = web_bigrams.get, reverse = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Europarl\n",
      "('of', 'the') 3822\n",
      "('in', 'the') 2108\n",
      "('to', 'the') 1386\n",
      "('the', 'european') 1293\n",
      "('on', 'the') 1229\n",
      "('it', 'is') 1182\n",
      "('that', 'the') 1099\n",
      "('and', 'the') 1007\n",
      "('the', 'commission') 908\n",
      "('for', 'the') 894\n"
     ]
    }
   ],
   "source": [
    "print(\"Europarl\")\n",
    "for i in range(10):\n",
    "    print(top_europarl[i], europarl_bigrams[top_europarl[i]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NewsCommentary\n",
      "('of', 'the') 2002\n",
      "('in', 'the') 1821\n",
      "('to', 'the') 864\n",
      "('’', 's') 784\n",
      "('and', 'the') 713\n",
      "('it', 'is') 584\n",
      "('that', 'the') 568\n",
      "('on', 'the') 548\n",
      "('the', 'us') 545\n",
      "('to', 'be') 541\n"
     ]
    }
   ],
   "source": [
    "print(\"NewsCommentary\")\n",
    "for i in range(10):\n",
    "    print(top_news[i], news_bigrams[top_news[i]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "OpenSubs\n",
      "('i', \"'m\") 2041\n",
      "('it', \"'s\") 1975\n",
      "('don', \"'t\") 1863\n",
      "('you', \"'re\") 1239\n",
      "('', 'i') 972\n",
      "('in', 'the') 961\n",
      "('that', \"'s\") 876\n",
      "('of', 'the') 805\n",
      "('i', \"'ll\") 779\n",
      "('i', 'don') 662\n"
     ]
    }
   ],
   "source": [
    "print(\"OpenSubs\")\n",
    "for i in range(10):\n",
    "    print(top_opensubs[i], opensubs_bigrams[top_opensubs[i]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TED Talks\n",
      "('of', 'the') 1925\n",
      "('in', 'the') 1733\n",
      "('this', 'is') 1036\n",
      "('and', 'i') 793\n",
      "('and', 'the') 777\n",
      "('going', 'to') 754\n",
      "('to', 'be') 723\n",
      "('to', 'the') 665\n",
      "('on', 'the') 633\n",
      "('is', 'a') 596\n"
     ]
    }
   ],
   "source": [
    "print(\"TED Talks\")\n",
    "for i in range(10):\n",
    "    print(top_ted[i], ted_bigrams[top_ted[i]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Web-Crawled\n",
      "('of', 'the') 2496\n",
      "('in', 'the') 1624\n",
      "('to', 'the') 1044\n",
      "('on', 'the') 759\n",
      "('and', 'the') 631\n",
      "('for', 'the') 585\n",
      "('at', 'the') 534\n",
      "('to', 'be') 521\n",
      "('with', 'the') 422\n",
      "('it', 'is') 417\n"
     ]
    }
   ],
   "source": [
    "print(\"Web-Crawled\")\n",
    "for i in range(10):\n",
    "    print(top_web[i], web_bigrams[top_web[i]])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Questions\n",
    "\n",
    "(1) Can you find the top trigrams for each corpus?\n",
    "\n",
    "(2) Can you compare the frequencies across corpora for each n-gram?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
